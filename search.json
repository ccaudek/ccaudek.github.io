[
  {
    "objectID": "blog/2021-10-01-sommatorie/index.html",
    "href": "blog/2021-10-01-sommatorie/index.html",
    "title": "Sommatorie",
    "section": "",
    "text": "Il simbolo \\(\\sum_{i=1}^{\\infty}\\) indica che dobbiamo assegnare al numero intero \\(i\\) tutti i suoi valori \\(1, 2, 3, ...\\) ed eseguire la somma dei termini. (Jean-Baptiste Joseph Fourier)\nLe somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. Si veda, ad esempio, Wikipedia."
  },
  {
    "objectID": "blog/2021-10-01-sommatorie/index.html#proprietà-1",
    "href": "blog/2021-10-01-sommatorie/index.html#proprietà-1",
    "title": "Sommatorie",
    "section": "Proprietà 1",
    "text": "Proprietà 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa: [ {i=1}^{n} a = {n~} = n a. ]"
  },
  {
    "objectID": "blog/2021-10-01-sommatorie/index.html#proprietà-2-proprietà-distributiva",
    "href": "blog/2021-10-01-sommatorie/index.html#proprietà-2-proprietà-distributiva",
    "title": "Sommatorie",
    "section": "Proprietà 2 (proprietà distributiva)",
    "text": "Proprietà 2 (proprietà distributiva)\nNel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con [ {i=1}^{n} a x_i = a x_1 + a x_2 + + a x_n ] è possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere [ {i=1}^{n} a x_i = a _{i=1}^{n} x_i. ]"
  },
  {
    "objectID": "blog/2021-10-01-sommatorie/index.html#proprietà-3-proprietà-associativa",
    "href": "blog/2021-10-01-sommatorie/index.html#proprietà-3-proprietà-associativa",
    "title": "Sommatorie",
    "section": "Proprietà 3 (proprietà associativa)",
    "text": "Proprietà 3 (proprietà associativa)\nNel caso in cui [ {i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + (a + x_n) ] si ha che [ {i=1}^{n} (a + x_i) = n a + {i=1}^{n} x_i. ] È dunque chiaro che in generale possiamo scrivere [ {i=1}^{n} (x_i + y_i) = {i=1}^{n} x_i + {i=1}^{n} y_i. ]"
  },
  {
    "objectID": "blog/2021-10-01-sommatorie/index.html#proprietà-4",
    "href": "blog/2021-10-01-sommatorie/index.html#proprietà-4",
    "title": "Sommatorie",
    "section": "Proprietà 4",
    "text": "Proprietà 4\nSe deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio, [ {i=1}^{n} x_i^2 = x_1^2 + x_2^2 + + x_n^2 ({i=1}^{n} x_i )^2. ]"
  },
  {
    "objectID": "blog/2021-10-01-sommatorie/index.html#proprietà-5",
    "href": "blog/2021-10-01-sommatorie/index.html#proprietà-5",
    "title": "Sommatorie",
    "section": "Proprietà 5",
    "text": "Proprietà 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo: [ _{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + + x_n y_n, ] infatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\)."
  },
  {
    "objectID": "blog/2021-10-01-la-campana-di-gauss/index.html",
    "href": "blog/2021-10-01-la-campana-di-gauss/index.html",
    "title": "La campana di Gauss",
    "section": "",
    "text": "Per iniziare, carichiamo i pacchetti necessari.\nlibrary(\"tidyverse\", warn.conflicts = FALSE)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(\"gghighlight\")"
  },
  {
    "objectID": "blog/2021-10-01-la-campana-di-gauss/index.html#la-funzione-di-ripartizione",
    "href": "blog/2021-10-01-la-campana-di-gauss/index.html#la-funzione-di-ripartizione",
    "title": "La campana di Gauss",
    "section": "La funzione di ripartizione",
    "text": "La funzione di ripartizione\n\ncurve(\n  pnorm(x), \n  xlim = c(-3.5, 3.5), \n  ylab = \"Probabilità\", \n  main = \"Funzione cumulativa della normale standardizzata\"\n)"
  },
  {
    "objectID": "blog/2021-10-01-la-campana-di-gauss/index.html#quantili-e-densità",
    "href": "blog/2021-10-01-la-campana-di-gauss/index.html#quantili-e-densità",
    "title": "La campana di Gauss",
    "section": "Quantili e densità",
    "text": "Quantili e densità\nDefiniamo i seguenti quantili e calcoliamo la densità corrispondente per il caso della normale standardizzata:\n\nquants &lt;- c(-1.96, 0, 1.96)\ngauss(quants, 0, 1)\n\n[1] 0.05844094 0.39894228 0.05844094\n\n\nLo stesso risultato si ottene con\n\ndnorm(quants, 0, 1)\n\n[1] 0.05844094 0.39894228 0.05844094"
  },
  {
    "objectID": "blog/2021-10-01-istogramma/index.html",
    "href": "blog/2021-10-01-istogramma/index.html",
    "title": "Istogramma",
    "section": "",
    "text": "In questo tutorial ci poniamo il problema di costruire un istrogramma utilizzando la funzione ggplot() del pacchetto ggplot2 in R. Vedremo quali sono i limiti degli istogrammi. Concluderemo introducendo una rappresentazione alternativa, la densità della frequenza dei dati, la quale attenua i limiti degli istogrammi."
  },
  {
    "objectID": "blog/2021-10-01-istogramma/index.html#istogramma",
    "href": "blog/2021-10-01-istogramma/index.html#istogramma",
    "title": "Istogramma",
    "section": "Istogramma",
    "text": "Istogramma\nCreiamo ora un istogramma usando i valori x.\nQual è l’altezza della barra in corrispondeza dell’intervallo (0,2]?\nLa base è pari a 2 e l’area è 5/8. Dunque l’altezza è\n\n(5 / 8) / 2\n\n[1] 0.3125\n\n\nUsiamo ggplot()\n\nx %&gt;%\n    as.data.frame() %&gt;%\n    ggplot(aes(x = x)) +\n    geom_histogram(\n        aes(y = after_stat(density)),\n        breaks = c(0, 2, 4, 6, 8)\n    )\n\n\n\n\n\n\n\n\nQuesto ci conferma che, di default, ggplot() usa intervalli chiusi a destra.\nCambiamo ora il default e specifichiamo intervalli chiusi a sinistra:\n\nx %&gt;%\n    as.data.frame() %&gt;%\n    ggplot(aes(x = x)) +\n    geom_histogram(\n        aes(y = after_stat(density)),\n        breaks = c(0, 2, 4, 6, 8),\n        closed = \"left\"\n    )"
  },
  {
    "objectID": "blog/2021-10-01-istogramma/index.html#visualizzazione-con-ggplot",
    "href": "blog/2021-10-01-istogramma/index.html#visualizzazione-con-ggplot",
    "title": "Istogramma",
    "section": "Visualizzazione con ggplot()",
    "text": "Visualizzazione con ggplot()\n\np1 &lt;- bysubj %&gt;%\n    ggplot(aes(x = bdi)) +\n    geom_histogram(\n        aes(y = after_stat(density)),\n        breaks = c(0, 13.5, 19.5, 28.5, 44.1) # il valore BDI-II massimo è 44\n    ) +\n    scale_x_continuous(breaks = c(0, 13.5, 19.5, 28.5, 44.1)) +\n    labs(\n        x = \"BDI-II\",\n        y = \"Densità di frequenza\"\n    )\np1\n\n\n\n\n\n\n\n\nÈ più comune, però, utilizzare classi di ampiezza uguale.\n\np2 &lt;- bysubj %&gt;%\n    ggplot(aes(x = bdi)) +\n    geom_histogram(\n        aes(y = after_stat(density)),\n        breaks = seq(0, 44.1, length.out = 7)\n    ) +\n    scale_x_continuous(breaks = c(0.00, 7.35, 14.70, 22.05, 29.40, 36.75, 44.10)) +\n    labs(\n        x = \"BDI-II\",\n        y = \"Densità di frequenza\",\n        caption = \"Fonte: Zetsche, Buerkner, & Renneberg (2020)\"\n    )\n\n\np1 + p2"
  },
  {
    "objectID": "blog/2021-10-01-istogramma/index.html#limite-dellistogramma",
    "href": "blog/2021-10-01-istogramma/index.html#limite-dellistogramma",
    "title": "Istogramma",
    "section": "Limite dell’istogramma",
    "text": "Limite dell’istogramma\nCome abbiamo notato sopra, uno dei limiti degli istogrammi è che il profilo dell’istogramma è arbitrario: a seconda del numero e dei limiti delle classi che vengono scelte, cambiano sia il numero che la forma delle barre dell’istogramma."
  },
  {
    "objectID": "blog/2021-09-26-manipolazione-dei-dati-con-dplyr/index.html",
    "href": "blog/2021-09-26-manipolazione-dei-dati-con-dplyr/index.html",
    "title": "Manipolazione dei dati con dplyr",
    "section": "",
    "text": "Aggiungo qui il link ad un video-tutorial che ho preparato relativamente alla manipolaizone dei dati usando le funzioni del pacchetto dplyr.\nNel video non faccio altro che commentare un tutorial predisposto da Allison Horst e disponibile seguendo questo link. Il tutorial di Allison Horst è fatto benissimo e non vedo ragioni di tradurlo o cambiarlo in qualche modo. Inoltre, se andate nella pagina web che ho indicato sopra, potete anche fare degli esercizi che vi consentono di verificare se avete capito come utilizzare in pratica le istruzioni R che vengono discusse – le risposte agli esercizi sono immediatamente disponibili il che rende il tutorial di Allison Horst un utilissimo strumento di apprendimento. Buon divertimento!"
  },
  {
    "objectID": "blog/2021-09-25-la-struttura-del-progetto/index.html",
    "href": "blog/2021-09-25-la-struttura-del-progetto/index.html",
    "title": "La struttura del progetto",
    "section": "",
    "text": "Di seguito riporto il link ad un breve video-tutorial che cerca di rispondere alle seguenti domande: come organizzo tutto il materiale che fa parte di un progetto? Quali sono i principi che devo seguire per assegnare i nomi ai file? Come devo organizzare i file nelle cartelle? L’obiettivo è quello di immagazzinare sul computer il lavoro che abbiamo fatto in maniera tale che, in futuro, sarà facile recuperare quello che ci serve. E in modo tale che sia facile lavorare al nostro progetto nel presente.\nLe considerazioni che faccio fanno riferimento a delle raccomandazioni che “sono nell’aria”, ovvero, che sono condivise da molte persone. Questo materiale è stato organizzato in una serie di video youtube da Danielle Navarro e io mi limito a commentare brevemente quello che lei dice. Ovviamente, invece di seguire il mio video-tutorial, potete guardare direttamente i video di Danielle Navarro.\nUna cosa che mi sono dimenticato di dire nel mio video, e che invece è presente nei video youtube, è la seguente: dove dobbiamo salvare la cartella che contiene tutto il materiale di un progetto? Pessime risposte a questa domanda sono: il Desktop oppure la cartella di Download. Peggio di così non si può fare. Perché sia il Desktop sia la cartella Download contengono informazioni transienti, ovvero file che butterete via ad un certo punto – presto, si spera. Invece la cartella che contiene il vostro progetto contiene il frutto del vostro lavoro – e certamente non volete cancellarla per sbaglio. Quindi, un’idea molto migliore è quella di salvare la cartella del progetto nella cloud, ovvero, sul vostro comupter in cartelle come OneDrive o Dropbox.\nSpero che questo sia utile.\n\nInformazioni sulla sessione di lavoro\n\n\nSession Info\n\nSono qui fornite le informazioni sulla sessione di lavoro insieme all’elenco dei pacchetti usati. I pacchetti contrassegnati con un asterisco(*) sono stati usati esplicitamente nello script.\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.2\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Rome\n date     2025-01-26\n pandoc   3.6.2 @ /opt/homebrew/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.3   2024-06-21 [1] CRAN (R 4.4.0)\n digest        0.6.37  2024-08-19 [1] CRAN (R 4.4.1)\n evaluate      1.0.3   2025-01-10 [1] CRAN (R 4.4.1)\n fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.0)\n htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.0)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.4.0)\n jsonlite      1.8.9   2024-09-20 [1] CRAN (R 4.4.1)\n knitr         1.49    2024-11-08 [1] CRAN (R 4.4.1)\n rlang         1.1.4   2024-06-04 [1] CRAN (R 4.4.0)\n rmarkdown     2.29    2024-11-04 [1] CRAN (R 4.4.1)\n rstudioapi    0.17.1  2024-10-22 [1] CRAN (R 4.4.1)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.4.0)\n xfun          0.50    2025-01-07 [1] CRAN (R 4.4.1)\n yaml          2.3.10  2024-07-26 [1] CRAN (R 4.4.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "blog/2021-09-20-stimatori-distorti-e-non-distorti-della-varianza/index.html",
    "href": "blog/2021-09-20-stimatori-distorti-e-non-distorti-della-varianza/index.html",
    "title": "Stimatori distorti e non distorti della varianza",
    "section": "",
    "text": "Ci sono due formule per la varianza:\n\\[\nS^2 = \\frac{\\sum_{i = 1}^n (X_i - \\bar{X})^2}{n}\n\\]\ne\n\\[\ns^2 = \\frac{\\sum_{i = 1}^n (X_i - \\bar{X})^2}{n - 1}\n\\] La prima formula è quella di una statistica, e si pone il problema di fornire descrizione sintetica di una proprietà del campione – in questo caso, la varianza.\nLa seconda formula è quella di uno stimatore, e si pone l’obiettivo di descrivere, nella maniera più fedele possibile, una proprietà della popolazione – in questo caso, la varianza – utilizzando le informazioni presenti nel campione.\nLa prima formula, quella con \\(n\\) al denominatore, fallisce nello scopo che la seconda formula si propone di raggiungere (ovvero, l’obiettivo di descrivere le proprietà della popolazione). Infatti, in media, produrrà una stima troppo piccola. Usiamo una simulazione per esaminare questa faccenda.\nIniziamo a definire le proprietà della popolazione.\n\nmu &lt;- 100 \nsigma &lt;- 15\n\nDecidiamo, inoltre, di considerare campioni di ampiezza \\(n\\) = 30.\n\nsample_size &lt;- 30\n\nNel caso di un singolo campione, per esempio, abiamo:\n\none_sample &lt;- rnorm(sample_size, mu, sigma) \nmean(one_sample)\n\n[1] 100.8664\n\nvar(one_sample)\n\n[1] 192.2824\n\n\nMa un singolo campione ci dice poco delle caratteristiche della “formula” che stiamo esaminando – quella che ha \\(n\\) al denominatore. Dato che è facile farlo con R, esaminiamo quello che succede quando consideriamo un milione di campioni:\n\nvar_distr &lt;- replicate(\n  1e6,\n    var(\n      rnorm(sample_size, mu, sigma) \n    ) * (sample_size - 1) / sample_size\n)\n\nLa funzione rnorm() estrae un campione casuale di ampiezza sample_size (ovvero, 30) da una popolazione normale di media 100 e deviazione standard 15. La varianza della popolazione è dunque\n\n15^2\n\n[1] 225\n\n\nLa funzione var() * (sample_size - 1) / sample_size calcola la varianza delle 30 osservazioni di un campione utilizzando la prima formula (con \\(n\\) al denominatore).\nLa funzione replicate() ripete un milione di volte questi calcoli, ovvero calcola la varianza di un milione di campioni casuali di ampiezza 30 estratti da una popolazione normale di media 100 e varianza \\(15^2\\). Ciò significa che l’oggetto var_distr conterrà un milione di numeri: le varianze calcolate con la prima formula, per un milione di campioni casuali estratti dalla popolazione di riferimento.\nQuanto bene ha funzionato la prima formula? Ovviamente, alcune volte (cioé, per alcuni campioni) meglio, altre volte peggio. Il valore più piccolo che abbiamo ottenuto è\n\nmin(var_distr)\n\n[1] 44.00988\n\n\ne il valore più grande che abbiamo ottenuto è\n\nmax(var_distr)\n\n[1] 604.1064\n\n\nIl valore medio – ovvero, il valore atteso del valore che si ottiene utilizzando la prima formula, è\n\nmean(var_distr)\n\n[1] 217.4179\n\n\nQuesto valore è chiaramente troppo piccolo. In altre parole, la prima formula, se venisse usata per stimare la varianza della popolazione produrrebbe una sottostima del valore del parametro cercato.\nSi può correggere questo errore sistematico?\nCertamente! E questo è lo scopo della seconda formula, quella con \\(n - 1\\) al denominatore. Ripetiamo la simulazione usando la seconda formula:\n\nvar_distr_c &lt;- replicate(\n  1e6,\n  var(\n    rnorm(sample_size, mu, sigma) \n  )\n)\n\nIn questo caso, il valore atteso è\n\nmean(var_distr_c)\n\n[1] 225.0316\n\n\nuguale al valore del parametro\n\n15^2\n\n[1] 225\n\n\nNella simulazione il risultato non è perfetto, ma si capisce che questa è, appunto, una simulazione: aumentando il numero delle ripetizioni si otterrebbe un valore sempre più simile al valore teorico. Ma non è necessario fare questo. La conclusione è chiara: la seconda formula ci fornisce uno stimatore corretto (ovvero, privo di errore sistematico) della varianza della popolazione. Per questa ragione dividiamo per (\\(n\\) - 1)."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Scienze e Tecniche Psicologiche\n\nPsicometria. Introduction to data analysis and statistical methods for psychological research.\nLaboratorio di valutazione psicologica. Hands-on training in psychological assessment techniques.\n\nPsicologia Clinica e della Salute e Neuropsicologia\n\nTesting Psicologico. Advanced course on psychological testing and measurement.\nLaboratorio di Testing Psicologico. Practical applications of psychological testing methodologies.\n\n\n\nMeditazione, Compassione e Gestione Emozionale per le Professioni di Aiuto\n\nTraining cognitivo e contemplativo per lo sviluppo della compassione. A course focused on cognitive and contemplative practices to cultivate compassion and emotional regulation in helping professions."
  },
  {
    "objectID": "teaching.html#postgraduate-specialization-course",
    "href": "teaching.html#postgraduate-specialization-course",
    "title": "Teaching",
    "section": "",
    "text": "Meditazione, Compassione e Gestione Emozionale per le Professioni di Aiuto\n\nTraining cognitivo e contemplativo per lo sviluppo della compassione. A course focused on cognitive and contemplative practices to cultivate compassion and emotional regulation in helping professions."
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "CaudekLab",
    "section": "",
    "text": "The CaudekLab engages in interdisciplinary research that investigates:\n\nIndividual differences in cognitive processes;\n\nCognitive processes in diverse clinical populations, including individuals with obsessive-compulsive disorder, eating disorders, depression, and psychopathy;\n\nLearning processes and cognitive control;\n\nMemory, attention, and perception;\n\nIntelligence;\n\nSelf-compassion;\n\nCognitive mechanisms underlying the reception of fake news;\n\nThe impact of surprise on mental processes;\n\nDevelopment and validation of psychometric instruments."
  },
  {
    "objectID": "lab.html#current-opportunities",
    "href": "lab.html#current-opportunities",
    "title": "CaudekLab",
    "section": "Current Opportunities",
    "text": "Current Opportunities\nSe sei interessato/a a lavorare con me come relatore, sia per la prova finale L-24 che per il progetto di tesi magistrale LM-51, non esitare a contattarmi via email. Sarò felice di discutere i tuoi interessi accademici, coinvolgerti in un progetto di ricerca del laboratorio e/o aiutarti a sviluppare un progetto personalizzato in linea con le tue esigenze e aspirazioni.\nIf you are interested in working with me as your advisor, feel free to reach out to me via email. I would be happy to discuss potential projects and provide guidance tailored to your academic interests."
  },
  {
    "objectID": "lab.html#visitors",
    "href": "lab.html#visitors",
    "title": "CaudekLab",
    "section": "Visitors",
    "text": "Visitors\nI warmly welcome visiting scholars and students to join my lab. While I currently do not have funding available to sponsor visitors, I would be delighted to host you if you can secure funding through your own institution or other sources. To explore this opportunity, please email me your CV and a detailed research plan so we can discuss potential collaborations further."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Corrado Caudek",
    "section": "",
    "text": "Welcome to my personal website!\nI am an Associate Professor of Psychometrics and Quantitative Psychology at the University of Florence, Italy. My research explores individual differences in cognitive styles and strategies, with a focus on associative learning deficits, eating disorders, and self-compassion. The overarching aim of my work is to contribute to the development of more effective intervention strategies for psychological disorders, both at the individual and population levels."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am an Associate Professor of Psychometrics and Quantitative Psychology at Università degli Studi di Firenze in Italy.\n\nShort Bio\nPrior to joining the University of Florence, I was a Postdoctoral Researcher at the Center for Neural Science at New York University, a Postdoctoral Researcher at University of Trieste, and an Associate Professor at University of Trieste.\n\n\nContact Me\nThe easiest way to get in touch with me is by email.\n\n\nLocation\nDipartimento NEUROFARBA, Università degli Studi di Firenze\nVia di San Salvi n. 12, Complesso di S. Salvi, Padiglione 26, Firenze, 50139, Italy.\n\n\nThanks for visiting my site!"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "In my recent research, I dive into the intricacies of psychopathology through the innovative lens of computational psychiatry, adopting dimensional approaches to better understand psychological traits and symptoms. My work bridges multiple domains, including personality disorders, obsessive-compulsive symptoms, psychopathy, and psychological resilience, offering insights that transcend traditional diagnostic boundaries.\nOne focus of my research explores individual differences in psychological resilience. I focus on how personality traits interact with self-compassion to influence how people respond to significant stressors. To capture the richness of these dynamics, I employ Ecological Momentary Assessment (EMA)—a method that collects data in real-world settings, revealing how behaviors and experiences unfold in the moment.\nAnother strand of my work is the Triarchic Model of Psychopathy, where I examine its external validity and predictive power across diverse contexts. For example, I investigate how psychopathy-related traits influence intimate partner dynamics or shape risk perception during global challenges like the COVID-19 pandemic.\nI also delve into “Not Just Right Experiences” (NJRE)—a fascinating psychological phenomenon that may serve as an endophenotype for obsessive-compulsive symptoms. My research investigates how these experiences connect with broader personality traits and clinical patterns, shedding light on their role in the spectrum of mental health and well-being.\nThrough these diverse research avenues, my goal is to uncover fundamental patterns underlying human behavior and to contribute to the development of personalized, evidence-based interventions that effectively address psychological disorders."
  },
  {
    "objectID": "research.html#publications",
    "href": "research.html#publications",
    "title": "Research",
    "section": "Publications",
    "text": "Publications\nA list of my publications can be found on Google Scholar, Orchid ID or Scopus."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Rescorla-Wagner\n\n\n\n\n\nUn semplice modello di apprendimento associativo. \n\n\n\n\n\n2021-10-02\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nBibliografia\n\n\n\n\n\nBibliografia della prova finale e della tesi di laurea magistrale. \n\n\n\n\n\n2021-10-01\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nIstogramma\n\n\n\n\n\nLa rappresentazione grafica della distribuzione dei dati. \n\n\n\n\n\n2021-10-01\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nIstruzioni prova finale L-24\n\n\n\n\n\nTutto quello che avreste voluto sapere sulla prova finale L-24 ma non avete mai osato chiedere. \n\n\n\n\n\n2021-10-01\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nLa campana di Gauss\n\n\n\n\n\nUna prima occhiata alla distribuzione gaussiana. \n\n\n\n\n\n2021-10-01\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nScrivere la tesi con R Markdown\n\n\n\n\n\nEvitare Word. \n\n\n\n\n\n2021-10-01\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nSommatorie\n\n\n\n\n\nNotazione sommatoria. \n\n\n\n\n\n2021-10-01\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduzione a R Markdown\n\n\n\n\n\nIntegrazione tra R e il linguaggio di markup Markdown. \n\n\n\n\n\n2021-09-26\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nManipolazione dei dati con dplyr\n\n\n\n\n\nTutorial sulle funzionalità di dplyr per la manipolazione dei dati. \n\n\n\n\n\n2021-09-26\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nLa struttura del progetto\n\n\n\n\n\nSalvare e assegnare un nome ai documenti di un progetto. \n\n\n\n\n\n2021-09-25\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nFacebook\n\n\n\n\n\nLa pagina Facebookd del laboratorio. \n\n\n\n\n\n2021-09-24\n\n\nCorrado Caudek\n\n\n\n\n\n\n\n\n\n\n\n\nStimatori distorti e non distorti della varianza\n\n\n\n\n\nDividere per n - 1. \n\n\n\n\n\n2021-09-20\n\n\nCorrado Caudek\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2021-09-24-facebook/index.html",
    "href": "blog/2021-09-24-facebook/index.html",
    "title": "Facebook",
    "section": "",
    "text": "È attiva la pagina facebook del laboratorio. Contiene informazioni su progetti in corso e presentazioni dei laureandi. È una creazione dei torocinanti del laboratorio."
  },
  {
    "objectID": "blog/2021-09-26-introduzione-a-r-markdown/index.html",
    "href": "blog/2021-09-26-introduzione-a-r-markdown/index.html",
    "title": "Introduzione a R Markdown",
    "section": "",
    "text": "Posto qui il link ad un breve video-tutorial sull’uso di R Markdown.\nLa migliore descrizione del flusso di lavoro (workflow) con R Markdown è fornita in questo capitolo di R for Data Science.\nPer chi ha bisogno di un’introduzione, risultano sicuramente utili anche le slide di Danielle Navarro."
  },
  {
    "objectID": "blog/2021-10-01-bibliografia/index.html",
    "href": "blog/2021-10-01-bibliografia/index.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Ho creato un breve video con le istruzioni per creare la bibliografia delle tesi di laurea. Ci sono tanti tutorial sul web per affrontare questo problema: le semplici considerazioni che fornisco qui sono un possibile punto di partenza.\nAl di là delle cose che dico qui, consiglio fortemente tutti i laureandi, triennali e magistrali, di scrivere la tesi di laurea in R Markdown, usando le indicazioni fornite in un altro post e, soprattutto, di utilizzare bibtex per la bibliografia, in modo tale essere sicuri di ottenere il risultato corretto senza doversi preoccupare di applicare le (complicate) regole APA – i ricercatori fanno così quando scrivono un articolo."
  },
  {
    "objectID": "blog/2021-10-01-istruzioni-prova-finale-l-24/index.html",
    "href": "blog/2021-10-01-istruzioni-prova-finale-l-24/index.html",
    "title": "Istruzioni prova finale L-24",
    "section": "",
    "text": "Mediante questo link potete accedere ad un video in cui rispondo a tutte le possibili domande che potreste avere su questo argomento. Descriverò la procedura che consiglio per realizzare l’elaborato finale e per preparare la presentazione orale. Una volta scritto l’elaborato finale seguendo queste istruzioni, potete iniziare a lavorare alla presentazione orale. Sulla presentazione orale riceverete poi altri feedback negli incontri settimanali con i laureandi che saranno specificamente dedicati a questo tema."
  },
  {
    "objectID": "blog/2021-10-01-scrivere-la-tesi-con-r-markdown/index.html",
    "href": "blog/2021-10-01-scrivere-la-tesi-con-r-markdown/index.html",
    "title": "Scrivere la tesi con R Markdown",
    "section": "",
    "text": "Seguendo questo link potete trovare un video-tutorial sull’uso di R Markdown per la scrittura della tesi di laurea. Il materiale che ho predisposto può essere scaricato selezionando questo link. Buon lavoro!"
  },
  {
    "objectID": "blog/2021-10-02-rescorla-wagner/index.html",
    "href": "blog/2021-10-02-rescorla-wagner/index.html",
    "title": "Rescorla-Wagner",
    "section": "",
    "text": "Regola di Rescorla-Wagner\nIl modello di Rescorla-Wagner fornisce una regola di apprendimento che descrive come cambia la forza associativa durante il condizionamento pavloviano. Supponiamo di prendere uno stimolo inizialmente neutro (ad es. un tono) e di associarlo a un risultato che ha un valore intrinseco per l’organismo (ad es. un premio – oppure una punizione). Col tempo l’organismo impara ad associare il tono al premio e risponderà al tono più o meno allo stesso modo in cui risponde al premio. In questo esempio il premio è lo stimolo incondizionato (US) e il tono è stimolo condizionato (SC).\nSecondo il modello Rescorla-Wagner, la regola per l’aggiornamento della forza associativa tra US e SC è basata sul divario tra l’aspettativa di ricompensa e il risultato che viene effettivamente ottenuto:\n\\[\nv_{s,t} = v_{s,t-1} + \\alpha \\cdot (\\lambda_{t-1} - v_{s,t-1}),\n\\] dove\n\n\\(v_{s,t}\\) è il valore dello stimolo \\(s\\) nella prova \\(t\\), che riflette l’aspettativa di una ricompensa,\n\\(\\lambda_{t-1}\\) è la ricompensa ricevuta nella prova \\(t-1\\),\n\\(\\alpha\\) è il tasso di apprendimento.\n\nPertanto, il valore assegnato ad uno stimolo viene aggiornato in base all’errore di previsione (la differenza tra il feedback ricevuto \\(\\lambda_{t-1}\\) e l’aspettativa di ricompensa \\(v_{s,t-1}\\)).\nIl tasso di apprendimento \\(\\alpha \\in [0, 1]\\) determina quanto viene pesato questo errore di previsione nell’aggiornamento dell’aspettativa di ricompensa alla luce del feedback che è stato ottenuto.\n\n\nCondizionamento\nPer chiarire il funzionamento della regola di Rescorla-Wagner la implementiamo in una funzione R:\n\nupdate_rw &lt;- function(value, alpha=0.15, lambda=1) {\n  value + alpha * (lambda - value)\n}\n\nIn una prima simulazione costituita da una sequenza di 40 prove esaminiamo come varia l’aspettativa di ricompensa dello stimolo \\(s\\) nel tempo. Immaginiamo che il feedback ottenuto sia sempre pari ad una ricompensa (\\(\\lambda = 1\\)). Nella prima prova, il valore dello stimolo è inizializzato a zero.\n\nn_trials &lt;- 40\nstrength &lt;- numeric(n_trials)\nstrength\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0\n\nfor(trial in 2:n_trials) {\n  strength[trial] &lt;- update_rw( strength[trial-1] )\n}\nprint(strength)\n\n [1] 0.0000000 0.1500000 0.2775000 0.3858750 0.4779937 0.5562947 0.6228505\n [8] 0.6794229 0.7275095 0.7683831 0.8031256 0.8326568 0.8577582 0.8790945\n[15] 0.8972303 0.9126458 0.9257489 0.9368866 0.9463536 0.9544006 0.9612405\n[22] 0.9670544 0.9719962 0.9761968 0.9797673 0.9828022 0.9853819 0.9875746\n[29] 0.9894384 0.9910226 0.9923692 0.9935139 0.9944868 0.9953138 0.9960167\n[36] 0.9966142 0.9971221 0.9975538 0.9979207 0.9982326\n\nplot(\n  1:n_trials, \n  strength, \n  type = 'l', \n  ylim = c(0,1),\n  xlab = \"Prove\",\n  ylab = \"Aspettativa di ricompensa\")\npoints(1:n_trials, strength)\n\n\n\n\n\n\n\n\nApplicando la regola di Rescorla-Wagner, il valore (ovvero, l’aspettativa di ricompensa) dello stimolo \\(s\\), nel caso di feedback positivi, aumenta progressivamente fino a raggiungere l’asintoto di 1. Nella simulazione precedente abbiamo posto \\(\\alpha = 0.15\\). Con \\(\\alpha = 0.5\\) otteniamo:\n\nstrength &lt;- numeric(n_trials)\n\nfor(trial in 2:n_trials) {\n  strength[trial] &lt;- update_rw(alpha = 0.5, strength[trial-1] )\n}\nplot(\n  1:n_trials, \n  strength, \n  type = 'l', \n  ylim = c(0,1),\n  xlab = \"Prove\",\n  ylab = \"Aspettativa di ricompensa\"\n)\npoints(1:n_trials, strength)\n\n\n\n\n\n\n\n\nÈ chiaro dunque che il parametro \\(\\alpha\\) determina la velocità con la quale viene aggiornata l’aspettativa di ricompensa.\n\n\nEstinzione\nConsideriamo ora l’estinzione dell’associazione che è stata appresa. In questa seconda simulazione, le prime 25 prove saranno identiche a quelle della simulazione precedente. In esse verrà sempre fornita una ricompensa (\\(\\lambda = 1)\\). Le ultime 25 prove, invece, forniranno un feedback negativo, ovvero, \\(\\lambda = 0\\) – possiamo immaginare il feedback come l’assenza di premio.\nQuello che ci aspettiamo di vedere in questa situazione è che dopo la prova 25, quando il premio viene rimosso, la forza dell’associazione inizi a indebolirsi perché l’agente sta ora associando il CS con l’assenza di premio (cioè il parametro \\(\\lambda\\) è sceso a zero e quindi l’associazione \\(v\\) ritorna lentamente al valore iniziale).\n\nn_trials &lt;- 50                \nstrength &lt;- numeric(n_trials) \nlambda &lt;- 1 # initial reward value \n\nfor(trial in 2:n_trials) {\n  \n  # remove the shock after trial 25\n  if(trial &gt; 25) {\n    lambda &lt;- 0\n  }\n  \n  # update associative strength on each trial\n  strength[trial] &lt;- update_rw(\n    value = strength[trial-1],\n    lambda = lambda\n  )\n}\n\nplot(\n  1:n_trials, \n  strength, \n  type = 'l', \n  ylim = c(0,1),\n  xlab = \"Prove\",\n  ylab = \"Aspettativa di ricompensa\"\n)\npoints(1:n_trials, strength)\n\n\n\n\n\n\n\n\nL’estinzione è efficace nel rimuovere l’associazione, ma la sua efficacia richiede del tempo, non è immediata. Se ci fermiamo alla 35-esima prova, per esempio, allo stimolo \\(s\\) sarà ancora associata una piccola aspettativa di ricompensa.\n\n\nRegola soft-max\nUna volta attribuita una aspettativa di ricompensa agli stimoli, l’agente deve scegliere tra i diversi stimoli che sono presenti. Potrebbe sembrare ovvio scegliere, tra i vari stimoli presenti, quello a cui è associata l’aspettativa di ricompensa più altra (“massimizzazione della probabilità”) in questo particolare compito. Ma gli organismi biologici non si comportano così. Piuttosto, tendono a scegliere più spesso lo stimolo a cui è associata l’aspettativa di ricompensa maggiore, ma non sempre. Ci sono marcate differenze individuali nella strategia di scelta che si colloca tra due estremi: un’estremo è quello in cui l’aspettativa di valore determina la scelta; l’altro estremo è quello in cui la scelta tra gli stimoli è puramente casuale (ovvero, non è in alcun modo determinata dall’aspettativa di ricompensa associata agli stimoli).\nPer descrivere il continuum tra queste due diverse strategie di scelta\nPer modellare il modo in cui gli agenti traducono i valori di aspettativa di ricompensa in una scelta, viene utilizzato un modello in grado di catturare queste diverse possibili strategie di scelta. A questo fine viene usata la cosiddetta equazione soft-max:\n\\[\np(s) = \\frac{\\exp(\\beta v_s)}{\\sum_i \\exp(\\beta v_i)}.\n\\] Se supponiamo che ci siano solo due stimoli, A e B, dove \\(v_B = 1 - v_A\\), allora otteniamo la situazione seguente.\n\nsoftmax &lt;- function(beta, x) {\n  1 / (1 + exp(-beta * x))\n}\n\n\nbeta &lt;- 5\nx &lt;- seq(-1, 1, length.out = 100)\ny &lt;- softmax(beta, x)\nplot(\n  x, \n  y, \n  type = 'l', \n  #ylim = c(0,1),\n  xlab = \"Valore (A) - valore (B)\",\n  ylab = \"p(scelta = A)\"\n)\n\n\n\n\n\n\n\n\nSi noti che\n\nLa probabilità di scegliere lo stimolo A aumenta in modo monotono con la differenza di valore A - B.\nLa funzione softmax ci dice che l’agente sceglierà lo stimolo A la maggior parte delle volte quando \\(v_A &gt; v_B\\), ma non sempre.\nDa qui deriva il termine ‘softmax’: l’agente sceglie lo stimolo con il valore maggiore la maggior parte delle volte (ma non sempre), quindi questa è una funzione di massimizzazione ‘soft’.\n\n\nInformazioni sulla sessione di lavoro\n\n\nSession Info\n\nSono qui fornite le informazioni sulla sessione di lavoro insieme all’elenco dei pacchetti usati. I pacchetti contrassegnati con un asterisco(*) sono stati usati esplicitamente nello script.\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.2\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Rome\n date     2025-01-26\n pandoc   3.6.2 @ /opt/homebrew/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.3   2024-06-21 [1] CRAN (R 4.4.0)\n digest        0.6.37  2024-08-19 [1] CRAN (R 4.4.1)\n evaluate      1.0.3   2025-01-10 [1] CRAN (R 4.4.1)\n fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.0)\n htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.0)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.4.0)\n jsonlite      1.8.9   2024-09-20 [1] CRAN (R 4.4.1)\n knitr         1.49    2024-11-08 [1] CRAN (R 4.4.1)\n rlang         1.1.4   2024-06-04 [1] CRAN (R 4.4.0)\n rmarkdown     2.29    2024-11-04 [1] CRAN (R 4.4.1)\n rstudioapi    0.17.1  2024-10-22 [1] CRAN (R 4.4.1)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.4.0)\n xfun          0.50    2025-01-07 [1] CRAN (R 4.4.1)\n yaml          2.3.10  2024-07-26 [1] CRAN (R 4.4.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  }
]