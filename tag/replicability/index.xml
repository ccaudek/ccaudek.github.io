<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>replicability | Welcoming Uncertainty</title>
    <link>/tag/replicability/</link>
      <atom:link href="/tag/replicability/index.xml" rel="self" type="application/rss+xml" />
    <description>replicability</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 03 Oct 2016 08:30:00 -0500</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>replicability</title>
      <link>/tag/replicability/</link>
    </image>
    
    <item>
      <title>Replicability crisis in psychology</title>
      <link>/post/2016/crisis/</link>
      <pubDate>Mon, 03 Oct 2016 08:30:00 -0500</pubDate>
      <guid>/post/2016/crisis/</guid>
      <description>&lt;p&gt;In case you haven&amp;rsquo;t heard it, the joke goes like this: not only the results of the research cannot be replicated, even the absence of replication cannot be replicated.&lt;/p&gt;
&lt;p&gt;Richard Horton put it very clearly:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The case against science is straightforward: much of the scientific literature, perhaps half,
may simply be untrue. Afflicted by studies with small sample sizes, tiny effects, invalid exploratory analyses, and flagrant conflicts of interest, together with an obsession for pursuing fashionable trends of dubious importance, science has taken a turn towards darkness.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Horton, R. (2015). What is medicine&amp;rsquo;s 5 sigma? &lt;em&gt;The Lancet&lt;/em&gt;, &lt;em&gt;385(9976)&lt;/em&gt;, 1380.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://andrewgelman.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andrew Gelman&amp;rsquo;s blog&lt;/a&gt; reports a long-lasting discussion on such topic, which is very interesting to follow. Although not everybody agrees,
the null-hypothesis-significance-testing (NHST) approach fares quite badly in this crisis, which is not only a crisis in psychology, obviously (actually, it seems much worse elsewhere).  Small effect sizes, small samples, small signal-to-noise ratios, and still the &lt;em&gt;p&lt;/em&gt;-value can, quite easily, be smaller than .05. The NHST was such a simple procedure: is it any wonder that it could only fail?  Should I wonder how the first-year psychology students would react, if we started teaching Bayesian statistic rather than the frequentist approach? Or, should I ask, when  will it happen?&lt;/p&gt;
&lt;p&gt;Well, apart from the NHST, apart from the degrees of freedom of the experimenter, the money that comes from  &amp;lsquo;observing&amp;rsquo; a given result rather than another, the garden of forking paths,  the bad decisions of the Government agencies that dictate the criteria for career progression in academia, I think that it is worthwhile to remember the provocation of Nelson, Simmons, and Simonsohn (2012), who proposed the Utopia in which researchers are allowed to publish only one paper per year.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Publication quantity is no longer a relevant dimension. This system incentivizes researchers to demonstrate that an effect is robust and generalizable, and hence true and important.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; if Hari Seldon arrived at work and the published literature was slimmer and more digestible, would he be worse off? Furthermore, rather than wondering about how to evaluate two job candidates who differ in quality and quantity, Seldon would instead see candidates who were matched on the latter, allowing him to entirely focus on the former. Finally, Hari can pursue his own work with improved clarity and focus. There is only one paper to write this year. He had better make it count.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What&amp;rsquo;s wrong with that?&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
